### [ReAct: Synergizing Reasoning and Acting in Language Models|2210.03629]
- [論文連結:](https://arxiv.org/abs/2210.03629)
- [Github網址](https://react-lm.github.io/)
- https://github.com/ysymyth/ReAct
# 摘要
- 要解決的問題
  - 雖然大型語言模型（LLM）在語言理解和互動式決策等任務中表現出了令人印象深刻的能力，但它們的推理（例如思維鏈提示）和行動（例如行動計劃生成）能力主要作為單獨的主題進行研究。
- 提出的新觀點
  - 在本文中，我們探索使用 LLM 以交錯的方式產生推理軌跡和特定於任務的動作，從而實現兩者之間更大的協同作用：推理軌跡幫助模型歸納、跟踪和更新行動計劃以及處理異常，而操作允許它與外部來源（例如知識庫或環境）交互，以收集附加資訊。 
- 成果
  - 我們將名為 ReAct 的方法應用於各種語言和決策任務，並證明其在最先進的基線上的有效性，以及比沒有推理或行動組件的方法提高的人類可解釋性和可信度。
  - 具體來說，在問答（HotpotQA）和事實驗證（Fever）方面，ReAct 透過與簡單的維基百科API 交互，克服了思維鏈推理中普遍存在的幻覺和錯誤傳播問題，並產生類似人類的任務解決軌跡，比沒有推理痕跡的基線更容易解釋。
  - 在兩個互動式決策基準（ALFWorld 和 WebShop）上，ReAct 的表現優於模仿和強化學習方法，絕對成功率分別為 34% 和 10%，同時僅用一兩個上下文範例進行提示。
